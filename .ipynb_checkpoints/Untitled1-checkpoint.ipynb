{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorboardX as tbx\n",
    "\n",
    "from src.models import BiLM, SoftmaxLoss\n",
    "from src.preprocessing import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLM test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = torch.tensor([[1, 3, 4, 5, 2, 0]\n",
    "                       , [1, 4, 3, 6, 4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sent.transpose(1, 0).view(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lm_model = BiLM(100, 10, 7)\n",
    "\n",
    "loss_func = SoftmaxLoss()\n",
    "\n",
    "forward_output, backword_output, c = bi_lm_model(inputs)\n",
    "\n",
    "loss = loss_func(forward_output, backword_output, sent)\n",
    "\n",
    "optimizer = torch.optim.SGD(bi_lm_model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8676)\n",
      "tensor(2.8327)\n",
      "tensor(2.7853)\n",
      "tensor(2.7352)\n",
      "tensor(2.6856)\n",
      "tensor(2.6375)\n",
      "tensor(2.5910)\n",
      "tensor(2.5462)\n",
      "tensor(2.5031)\n",
      "tensor(2.4617)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    epoch_loss = 0.0\n",
    "    for batch in range(10):\n",
    "        #inputs, target = batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        forward_output, backword_output, c = bi_lm_model(inputs)\n",
    "        loss = loss_func(forward_output, backword_output, sent)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1117, -0.0517, -0.1969,  0.2721, -0.1754,  0.4400, -0.3322,  0.1445,\n",
       "          -0.0375,  0.5117],\n",
       "         [ 0.7798,  0.2518, -0.4081,  0.4856, -0.0018,  0.7685,  0.0832,  0.0889,\n",
       "          -0.4110,  1.3958]], grad_fn=<SliceBackward>),\n",
       " tensor([[-1.3118, -0.1223,  0.1932, -0.8429,  0.0526, -0.4303, -0.2412,  0.4959,\n",
       "          -0.3689,  0.3246],\n",
       "         [-1.8531, -0.0904,  0.0867, -0.9414, -0.1572, -0.5205, -0.3179,  0.4663,\n",
       "          -0.6213,  0.2895]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0, :, :], c[1, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    ['All', 'work', 'and', 'no', 'play'],\n",
    "    ['makes', 'Jack', 'a', 'dull', 'boy', '.'],\n",
    "    ['MAKE', 'AMERICA', 'GREAT', 'AGAIN'],\n",
    "    ['Poyoi']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_BOS_EOS(sentences):\n",
    "    _sents = sentences.copy()\n",
    "    for s in _sents:\n",
    "        s.insert(0, '<BOS>')\n",
    "        s.append('<EOS>')\n",
    "    \n",
    "    return _sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 5, 6, 7, 8, 2],\n",
       " [1, 9, 10, 11, 12, 13, 14, 2],\n",
       " [1, 15, 16, 17, 18, 2],\n",
       " [1, 19, 2]]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_word(sentences)\n",
    "\n",
    "sentences = attach_BOS_EOS(sentences)\n",
    "sentences = tokenizer.transform_word(sentences)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size):\n",
    "    data_size = len(data)\n",
    "    num_batches = math.ceil(data_size / batch_size)\n",
    "    \n",
    "    shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "    shuffle_data = np.array(data)[shuffle_indices]\n",
    "    for batch_num in range(num_batches):\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "        batch_X = shuffle_data[start_index:end_index]\n",
    "        batch_X = pad_sequences(batch_X, padding='post')\n",
    "        \n",
    "        yield (batch_num + 1), batch_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[ 1  9 10 11 12 13 14  2]\n",
      " [ 1 15 16 17 18  2  0  0]]\n",
      "2\n",
      "[[ 1 19  2  0  0  0  0]\n",
      " [ 1  4  5  6  7  8  2]]\n"
     ]
    }
   ],
   "source": [
    "for i, x in batch_generator(sentences, 2):\n",
    "    print(i)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_lm_model = BiLM(100, 10, len(tokenizer.vocab_word))\n",
    "loss_func = SoftmaxLoss()\n",
    "optimizer = torch.optim.SGD(bi_lm_model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4018)\n",
      "tensor(0.4035)\n",
      "tensor(0.3825)\n",
      "tensor(0.4014)\n",
      "tensor(0.4423)\n"
     ]
    }
   ],
   "source": [
    "#writer = tbx.SummaryWriter()\n",
    "\n",
    "batch_size = 2\n",
    "num_batches = math.ceil(len(sentences) / batch_size)\n",
    "\n",
    "for epoch in range(5):\n",
    "    epoch_loss = 0.0\n",
    "    for i, data in batch_generator(sentences, batch_size):\n",
    "        # data shape: (batch_size, timestamp)\n",
    "        data = torch.tensor(data).long()\n",
    "        \n",
    "        # inputs shape: (timestamp, batch_size)\n",
    "        inputs = data.transpose(1, 0).view(-1, data.shape[0])\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        forward_output, backword_output, c = bi_lm_model(inputs)\n",
    "        loss = loss_func(forward_output, backword_output, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #writer.add_scalar('loss', loss.data, global_step=(epoch * batch_size + i))\n",
    "        epoch_loss += loss.data\n",
    "    \n",
    "    print(epoch_loss / num_batches)\n",
    "    \n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
